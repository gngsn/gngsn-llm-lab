{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "- **Runnable 프로토콜**\n",
    "LangChain의 \"Runnable\" 프로토콜은 사용자가 사용자 정의 체인을 쉽게 생성하고 관리할 수 있도록 설계된 핵심적인 개념. \n",
    "이 프로토콜을 통해, 개발자는 일관된 인터페이스를 사용하여 다양한 타입의 컴포넌트를 조합하고, 복잡한 데이터 처리 파이프라인을 구성할 수 있음. \n",
    "- **Runnable 프로토콜 주요 메소드**\n",
    "  - `invoke`: 주어진 입력에 대해 체인을 호출하고, 결과 반환. 단일 입력에 동기적으로 작동.\n",
    "  - `batch`: 입력 리스트에 대해 체인을 호출하고, 각 입력에 대한 결과를 리스트로 반환. 여러 입력에 대해 동기적으로 작동. 효율적인 배치 처리.\n",
    "  - `stream`: 입력에 대해 체인을 호출하고, 결과의 조각들을 스트리밍. 대용량 데이터 처리나 실시간 데이터 처리에 유용.\n",
    "- **비동기 지원**: `ainvoke`, `abatch`, `astream` 메소드는 각각의 동기 버전에 대한 비동기 실행을 지원.   \n",
    "\n",
    "\n",
    "# RAG\n",
    ": Retrieval Augmented Generation\n",
    "\n",
    "### Retrieval Augmented Generation\n",
    "\n",
    "- 2020년, Facebook AI(FAIR)는 RAG를 제안한 논문 발표\n",
    "- 외부 데이터베이스에서 정보 검색(Retrieval) 후 컨텍스트를 추가(Augmented)하여 정답을 생성(Generation)\n",
    "  - 외부 지식 활용\n",
    "  - 증거 기반 생성\n",
    "  - 환각 감소\n",
    "\n",
    "### LLM Accuracy Optimization\n",
    "\n",
    "#### Context Optimization\n",
    "- 외부 지식이 필요한 경우\n",
    "- 최신 지식이 필요한 경우\n",
    "\n",
    "#### LLM Optimization\n",
    "- 일관적이지 않은 형식으로 생성\n",
    "- 말투나 스타일이 적절하지 않은 경우\n",
    "\n",
    "\n",
    "https://vitalflux.com/how-indexing-works-in-llm-based-rag-applications/\n",
    "Load > Split > Embed > store\n",
    "\n",
    "- **Document loaders**: 문서 객체를 로드하기 위해 설계된 도구\n",
    "- **Text splitters**: 텍스트를 Indexing 할 수 있는 작은 Chunk로 분할\n",
    "- **Embedding models**: 텍스트 데이터를 입력 받아 벡터 값을 생성\n",
    "- **Vector stores**: 벡터 및 관련 메타데이터를 저장하고 효율적으로 검색\n",
    "\n",
    "\n",
    "# LLM Agent\n",
    "\n",
    "*스스로 판단하고 문제를 해결하는 AI*\n",
    "\n",
    "### LLM Chain이 적합한 시나리오\n",
    "- 싱글턴(Single-Turn) 질의응답\n",
    "- 고정적인 워크플로우\n",
    "\n",
    "### 워크플로우 예시\n",
    "- 유저입력\n",
    "- PromptTemplate 채우기\n",
    "- LLM 호출\n",
    "(Optional) 응답 후처리\n",
    "\n",
    "\n",
    "### LLM Agent가 할 수 있는 것\n",
    "#### LLM Chain이 구현하기 어려운 시나리오\n",
    "- Human-In-The-Loop\n",
    "- Agent Routing\n",
    "- Tool Binding\n",
    "\n",
    "#### LLM Chain의 한계를 극복!\n",
    "- Human-In-The-Loop\n",
    "- Agent Routing\n",
    "- Tool Calling\n",
    "\n",
    "\n",
    "# Agent\n",
    "\n",
    "- 무수히 많은 Agent 패턴이 존재\n",
    "- 답변 생성속도에 대한 Trade-Off\n",
    "\n",
    "\n",
    "## Agent: 다양한 정의\n",
    "\n",
    "> Agents are systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks.\n",
    "\n",
    "> An AI agent is a system that uses an LLM to decide the control flow of an application.\n",
    "\n",
    "> “나한테 필요한 일을 알아서 해주면 좋겠다…”\n",
    "\n",
    "> “환경과 상호작용하며 목표 달성을 위해 필요한 작업을 주체적으로 판단하여 수행하는 프로그램”\n",
    "\n",
    "- 주체적으로 판단하기\n",
    "- 요청받은 추상적인 작업 → 명확하고 작은 작업 (divide-and-conquer)\n",
    "\n",
    "#### 주요 구성요소\n",
    "\n",
    "- **Planning**: 단위 작업 식별\n",
    "- **Tool Call**: 수행 (정보획득 / 외부 상호작용)\n",
    "- **Reflection**: 결과 평가\n",
    "- **Memory**: Multi-Step 구현을 위한 기억장치\n",
    "\n",
    "\n",
    "## 다양한 Agent 패턴\n",
    "\n",
    "### ReAct\n",
    "- link: https://www.promptingguide.ai/kr/techniques/react\n",
    "- ReAct = Reason + Act\n",
    "- 충분한 답변이 가능할 때 까지 [생각 → 행동 → 관찰] 사이클 반복 \n",
    "\n",
    "```\n",
    "Q. “Apple Remote는 어떤 기기와 상호작용하기 위해 처음 설계되었나요?”\n",
    "\n",
    "생각 1 → “Apple Remote가 처음 어떤 기기와 상호작용하기 위해 설계되었는지 알아내야 해.”\n",
    "행동 1 → 검색 [Apple Remote]\n",
    "관찰 1 → Apple Remote는 2005년에 Apple에서 발표한 리모트 컨트롤로, 초기에는 Front Row 소프트웨어와 함께 작동하도록 설계되었습니다. \n",
    "\n",
    "생각 2 → “Apple Remote가 처음에는 Front Row 소프트웨어와 상호작용하기 위해 설계되었구나. 하지만 Front Row 가 구체적으로 어떤 장치에서 \t\t\t\t\t\t\t사용되는지 확인해야 해.”\n",
    "행동 2 → 검색[Front Row software]\n",
    "관찰 2 → Front Row는 Apple의 미디어 센터 소프트웨어로, 주로 iMac과 Apple TV와 함께 사용되었습니다.\n",
    "\n",
    "생각 3 → “이제 답을 얻었어. Apple Remote는 처음에 iMac과 Apple TV와 상호작용하기 위해 설계되었어.”\n",
    "행동 3 → 완료 [iMac and Apple TV]\n",
    "```\n",
    "\n",
    "### Reflexion\n",
    "- link: https://www.promptingguide.ai/kr/techniques/reflexion\n",
    "\n",
    "\n",
    "- 생성한 답변에 대해 스스로 비판하고 수정하는 프로세스\n",
    "- 충분한 답변이 가능할 때 까지 [생성 → 평가/비판 → 수정] 사이클 반복 \n",
    "\n",
    "```\n",
    "Q.”시험을 잘 보려면 어떻게 해야할까?”\n",
    "\n",
    "Generation 1 → “효율적인 공부법을 찾아 최대한 집중하고, 필요하면 기억력과 문제 해결 능력을 향상시키는 전략을 사용하세요”\n",
    "\n",
    "Critique 1 → ＂너무 추상적이야. 구체적인 예시가 필요할 것 같아.”\n",
    "\n",
    "Generation 2 → “시험에 자주 나오는 내용을 포스트잇에 적어 책상과 벽에 붙이세요. 기출문제를 많이 풀어보는것이 중요합니다.”\n",
    "\n",
    "Critique 2 → ”어떤 내용이 시험에 자주 나오는지에 대해 보완이 필요해”\n",
    "\n",
    "Generation 3 → “교수님이 강조하신 내용을 포스트잇에 적어 책상과 벽에 붙이고 완벽히 암기하세요. 기출문제를 많이 풀어보는것이 중요합니다.”\n",
    "```\n",
    "\n",
    "\n",
    "### LATS\n",
    "- link: https://langchain-ai.github.io/langgraph/tutorials/lats/lats/\n",
    "\n",
    "\n",
    "\n",
    "#### Ref\n",
    "https://github.com/langchain-ai/langgraph/tree/main/docs/docs/tutorials\n",
    "https://langchain-ai.github.io/langgraph/tutorials/\n",
    "https://www.promptingguide.ai/kr/techniques\n",
    "\n",
    "\n",
    "## LangGraph\n",
    "\n",
    "주요 개념\n",
    "### 1. State\n",
    "\n",
    "- 그래프가 답변을 생성하기 위해 단위 작업에 의해 업데이트되고 / 참조되며 \"시작\"부터 \"끝\"까지 유지되는 메모리\n",
    "\n",
    "```python\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages] \n",
    "    documents: Document\n",
    "    started_at: datetime\n",
    "```\n",
    "\n",
    "- **Ref**: https://langchain-ai.github.io/langgraph/concepts/low_level/\n",
    "\n",
    "\n",
    "### 2. Node\n",
    "\n",
    ": 단위작업(LLM Chain, RAG, Tool)을 수행하는 요소\n",
    "\n",
    "**LangGraph Special Node**\n",
    "- `START`: 워크플로우 시작점\n",
    "- `END`: 워크플로우 종료지점\n",
    "\n",
    "```python\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "graph.add_edge(START, \"somewhere_begin\")\n",
    "graph.add_edge(\"somewhere_end\", END)\n",
    "```\n",
    "\n",
    "\n",
    "#### 사용자 정의 Node\n",
    "- state, config 입력 \n",
    "- 업데이트된 state를 반환\n",
    "\n",
    "```python\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages] \n",
    "\n",
    "\n",
    "def custom_node(state: State, config: RunnableConfig) -> dict: \n",
    "    resp = some_model_chain(state.messages[-1]) \n",
    "    return {\"messages\": [resp]}\n",
    "```\n",
    "\n",
    "#### State Reducer\n",
    "- link: https://langchain-ai.github.io/langgraph/how-tos/state-reducers/\n",
    "\n",
    "`messages: **Annotated[Sequence[BaseMessage], add_messages]**`\n",
    "\n",
    "- Node가 반환한 정보를 State에 어떻게 업데이트 할지 정의\n",
    "- lhs, rhs reduce 연산을 정의\n",
    "- langgraph.graph.message.add_messages는 Node가 반환한 정보를 State에 Append\n",
    "\n",
    "\n",
    "### LangGraph Node\n",
    "\n",
    "#### LangGraph prebuilt Node\n",
    "- **ToolNode**: 다수의 Tool을 병렬(thread)수행\n",
    "- **ValidationNode**: Tool 수행 전 호출 스키마에 대한 예외처리\n",
    "\n",
    "#### Graph에 Node 추가\n",
    "- State graph 정의\n",
    "- Node 추가\n",
    "\n",
    "```python\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    " \n",
    "def custom_node(state: State, config: RunnableConfig) -> dict:\n",
    "    resp = some_model_chain(state.messages[-1])\n",
    "    return {\"messages\": [resp]}\n",
    "\n",
    "graph = StateGraph(State) \n",
    "graph.add_node(\"custom\", custom_node)\n",
    "```\n",
    "\n",
    "### 3. Edge\n",
    "\n",
    "- 단위작업(Node)의 순서를 정의\n",
    "- 유향(Directed) 그래프\n",
    "\n",
    "#### 종류\n",
    "- Normal Edge: Source Node와 Destination Node를 연결\n",
    "- Conditional Edge: State에 따라 가변적인 Edge Routing\n",
    "\n",
    "```python\n",
    "# Normal Edge\n",
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_node(\"밥먹기\", eat())\n",
    "graph.add_node(\"씻기\", wash())\n",
    "graph.add_node(\"출근하기\", go_to_work())\n",
    "\n",
    "graph.add_edge(START, \"밥먹기\")\n",
    "graph.add_edge(\"밥먹기\", \"씻기\")\n",
    "graph.add_edge(\"씻기\", \"출근하기\")\n",
    "graph.add_edge(\"출근하기\", END)\n",
    "\n",
    "# Conditional Edge\n",
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_node(\"밥먹기\", eat)\n",
    "graph.add_node(\"씻기\", wash)\n",
    "graph.add_node(\"출근하기\", go_to_work)\n",
    "graph.add_node(\"연차\", day_off)\n",
    "\n",
    "# 연차 or 밥먹기 로 routing\n",
    "graph.add_conditional_edges(START, route_func)\n",
    "\n",
    "graph.add_edge(\"밥먹기\", \"씻기\")\n",
    "graph.add_edge(\"씻기\", \"출근하기\")\n",
    "graph.add_edge(\"출근하기\", END)\n",
    "```\n",
    "\n",
    "### ~~4. Event~~"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
